# -*- coding: utf-8 -*-
"""l216298_assignment_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JtU5pWsIK7mD-UnBSo8LRxFWSFSHLUSI

# Introduction To Data Science ‚Äì Assignment 2

---

#### Sections A ‚Äì B ‚Äì C ‚Äì D

---

##***Instructions: Read These Carefully Before Starting!***

1. Due Date: Thursday 20th October 2022 ‚Äì 11:59PM

2. **Name the file in the format Lyyxxxx_A2.ipynb and save it as .ipynb (e.g. L216666_A2.ipynb)**

3. Submission will be taken on Google Classroom (**submit SINGLE .ipynb file ONLY**)

4. **Assignment will not be evaluated if**:

> * You submit python (.py) files
> * You submit multiple .ipynb files
> * You submit compressed (.rar or .zip) files

5. **Work in the spaces provided and do not delete/modify any cells from this template.**

6. Upload data files directly to Google Colab - do not use Google Drive or GitHub linking method

*Not following these instructions will lead to mark deduction.*

---

All source files needed to complete this assignment can be found on the following [Google Drive link](https://drive.google.com/drive/folders/1qBib_6ZOhvHb73ZRLWiCMWl9NFyU1IDO?usp=sharing). Download these files and upload them to your Google Colab Notebook. 

**Do not link Google Drive or GitHub with Colab.**

**Do not add these files with your submission on Google Classroom.**

---

Happy Coding üå∫

---

TA Emails

Section A, C - Muhammad Maarij l192347@lhr.nu.edu.pk

Section B, D - Hira Ijaz l192377@lhr.nu.edu.pk

---

---
## Question 0

Add all library imports here
"""

from sklearn.linear_model import LinearRegression
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

"""---
## Question 1

####Single Linear Regression with Gradient Descent

> Take help from slides 26 and 30
---

**Part A -**
Write a function that calculates and returns value for hypothesis $h_\theta(x)$
"""

# complete this function implementation
#hyp=0o+01.x
def hypothesis(x, theta):
  hypothesiss= theta[0]+theta[1]*x
  return hypothesiss

"""**Part B -**
Write a function that calculates and returns value for loss/cost $J(\theta_0, \theta_1)$
"""

def loss(hypothesis_x, y):
  m = len(hypothesis_x)
  return  sum([(hypothesis_x[i] - y[i])**2 for i in range(m)]) * (2 / m)

"""**Part C-**
Write a function that applies the gradient descent algorithm and updates values of $\theta_0$ and $\theta_1$ until they converge.

* take default vaue of $Œ±$ to be 0.015
* take default number of iterations to be 15000
* print loss after every 500 iterations
"""

# complete this function implementation
def gradientdescent(x, y, theta, num_iterations=15000, alpha=0.015):
    m = x.size
    for j in range(num_iterations):
        h = []
        for num in x:
            h.append(hypothesis(num, theta))
        derivative_0 = sum([(hypothesis(x[i], theta) - y[i]) for i in range(m)])
        derivative_1 = sum([(hypothesis(x[i], theta) - y[i])*x[i] for i in range(m)])
        theta[0] = theta[0] - alpha * (1 / m) * derivative_0
        theta[1] = theta[1] - alpha * (1 / m) * derivative_1
        # report
        if j % 500 == 0:

            print('loss:', loss(h, y))

"""**Part D -**
FactoryRevenue.csv contains information about the number of workers in a factory and the annual profit for that factory. Import the file FactoryRevenue.csv as a Pandas DataSet and print out the information for it.
"""

import pandas as pd
factory=pd.read_csv("/content/Update_FactoryRevenue.csv")
factory

"""**Part E -**
Remove rows that have any null values
"""

"""print(factory)
print("Number of Rows Before: ",factory.shape[0])
print("Number of rows containing null data:",factory.isnull().sum().sum())
factory.dropna(axis=0, inplace=True)
print("Number of rows containing null data after removal:",factory.isnull().sum().sum())
print("Number of Rows After: ",factory.shape[0])"""
print("\nNumber of rows: ", factory.shape[0])
data = factory.dropna()
data.info()

"""**Part F -**

First identify the independant and dependant variables. 

Then create two arrays named x and y and add independant variable data to array x, dependant variable data to array y.
"""

# independant variable:TOTAL FACTORY WORKERS
# dependant variable:ANNUAL PROFIT
"""print("\n")
print("Independent Variable")
factory=factory[["TotalFactoryWorkers"]]
print(factory.head)
print("\n")
factoryy=pd.read_csv("/content/FactoryRevenue.csv")
print("Dependent Variable")
factoryy=factoryy[["AnnualProfit"]]
print(factoryy.head)"""
# independant variable: TotalFactoryWorkers
# dependant variable: AnnualProfit
x =  factory["TotalFactoryWorkers"].to_numpy()
print(x)
y =  factory["AnnualProfit"].to_numpy()
print(y)

"""**Part G -** 

Create an array called 'theta' that will hold $Œ∏_0$ and $Œ∏_1$. Initalize both values to 0.

Then call the gradientDescent function using array x, array y, and array theta. Do not provide any other input parameters.

Print out the values of y-intercept and slope/gradient
"""

theta = [0,0]
gradientdescent(x, y, theta)
print("Y-intercept:",theta[0])
print("Slope:",theta[1])

"""**Part H -** Plot a scatter plot and regression line on the same graph"""

"""import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn import linear_model
import io
plt.scatter(factory["TotalFactoryWorkers"], factory["AnnualProfit"])
plt.plot(x, theta[0] + theta[1]*x, color='red')
plt.title("Regression")
plt.xlabel("TotalFactoryWorkers")
plt.ylabel("AnnualProfit")
plt.show()"""
plt.scatter(factory["TotalFactoryWorkers"], factory["AnnualProfit"])
plt.plot(x, theta[0] + theta[1]*x, color='red')
plt.title("Regression")
plt.xlabel("TotalFactoryWorkers")
plt.ylabel("AnnualProfit")
plt.show()

"""---
## Question 2

Logistic Regression on Flowers Dataset

---

**Part A** - Load the file FlowersData.csv and describe the dataset
"""

import pandas as pd
flower=pd.read_csv("/content/FlowersData.csv")
flower

"""**Part B** - Split data into training and test data using SKLearn train_test_split. Specify parameter test_size to be 25%

Hint: You will be needing 4 arrays: X_train, X_test, y_train, y_test
"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

flower=pd.read_csv("/content/FlowersData.csv")
flower["flower_name"].unique()
flower["flower_name"]=flower["flower_name"].replace({'hibiscus':1,'daffodil':2,'lily':3})
X_train, X_test, y_train, y_test = train_test_split(flower[['sepal_length','sepal_width','petal_length','petal_width']],flower['flower_name'], test_size=0.25)
X_train

"""**Part C** - Perform scaling on the X_test and X_train values using StandardScacler from SKLearn Library"""

from sklearn import linear_model
mymodel = linear_model.LogisticRegression(max_iter=112)
mymodel.fit(X_train,y_train)

"""**Part D** - Train Model using SKLearn LogisticRegression"""

mymodel.predict(X_test)
X_test
#mymodel.predict(X_test)

"""**Part E** - Predict Labels for test split"""

predicted_output=mymodel.predict(X_test)
predicted_output

"""---
## Question 3

Confusion Matrix Construction

---

**Part A** - Using the prediction result of logistic regression (Question 2) construct a confusion matrix using SKLearn confusion_matrix

Print out this confusion matrix
"""

from sklearn.metrics import confusion_matrix
confusion_matrixx=confusion_matrix(y_test,predicted_output)
confusion_matrixx

"""**Part B** - Calculate and print Accuracy"""

#TP=CELL 1=14
TP=7
#TN=CELL 5+6+8+9
TN=13+1+0+10
#FN=CELL 4+6
FN=0+1
#FP=CELL 2+8
FP=0+0
Accuracy=(TP+TN)/(TP+TN+FN+FP)
print(Accuracy)
Acuuracy_in_percent=Accuracy*100
print(Acuuracy_in_percent)

"""**Part C** - Calculate and print Recall"""

Recall=(TP)/(TP+FN)
print(Recall)

"""**Part D** - Calculate and print Precision"""

Precision=(TP)/(TP+FP)
print(Precision)

"""**Part E** - Calculate and print $ùêπ_1$ Score"""

Fscore=(2*Precision*Recall)/(Precision+Recall)
print(Fscore)